
\documentclass[11pt]{report}
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{microtype}
\usepackage{lscape}

\usepackage[textwidth=17cm, textheight=21.2cm]{geometry}

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\usepackage{epstopdf}

\usepackage[sectionbib,numbers,sort&compress]{natbib}

\usepackage{subfigure}
\usepackage{multirow}
\usepackage{float}
\usepackage{soul}
\usepackage{xcolor}
%\graphicspath{{./images/}}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bm}

\usepackage{appendix}

\bibpunct[, ]{[}{]}{,}{}{,}{,}
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}

\setlength{\parskip}{0.5em}
\renewcommand{\baselinestretch}{1.1}

\renewcommand{\bibname}{References}

\usepackage{dashrule}

\usepackage{bibentry}
\bibliographystyle{apalike}

\makeatletter 
\renewcommand\BR@b@bibitem[2][]{\BR@bibitem[#1]{#2}\BR@c@bibitem{#2}}           
\makeatother

\nobibliography*

\begin{document}


We would like to thank the reviewers for their thorough comments and valuable feedback, which has helped us a lot in improving the paper. First, a summary of the improvements, changes, and new insights achieved during the revision are outlined. Then, all comments are addressed in a point-by-point manner, with separate replies to each reviewer. 
Throughout, comments or the reviewers are hightlighted in bold.

\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

\subsection*{Summary of the updates and insights}

{\color{blue} Paul: This list is way too long and detailed and appears to be redundant at times. I recommend focusing on between 4 and 7 or so points but more will be too much.}

\begin{itemize}

\item We have improved the paper significantly, including new insights from new experiments and analysis. The readability of Sections 4 and 5 have also been improved.

\item A discussion about the theoretical evidence of the near linear proportionality between the setting parameters of the model has been added (Section 4.2). 

\item In the first submission of the paper, the relationships between the setting parameters of the model were analyzed by simulation experiments and presented in form of graphs. 

\item We have derived numerical equations that characterize the relationships between the setting parameters of the model, which are useful to automatize updating the parameters in the fitting process (Section 4.3.1). 

\item The diagnostic rule that allowed to check whether the approximation was sufficiently accurate has been further discussed regarding its reliability and applicability (Sections 4.5).

\item A diagnostic procedure based on iterative steps to fit and diagnose the approximation has been proposed (Section 4.5.1), which is based on:

\begin{enumerate}
\item Recommendations to set initial values for the parameters.
\item Safety diagnostic rules to check if the approximation is sufficiently accurate (Sections 4.5).
\item Numerical equations to update and find out the optimal values for the parameters (Sections 4.3.1).
\end{enumerate}

\item The proposed diagnostic procedure is a safety, general and extensive procedure that allows us to automatize the fitting process.

\item A thorough analysis of the performance of the diagnostic tool has been carried out (Section 4.6).

\item The diagnostic tool has been extended to add the analysis for the Mat\'ern-5/2 kernel. So the whole study finally provides the diagnostics for a squared exponential, Mat\'ern-3/2, Mat\'ern-5/2 (Sections 4.3 and 4.3.1), and periodic squared exponential (Sections 3.3, 4.4 and Appendix C) covariance functions. 

\item By analyzing the constants characterizing the relationships for each covariance function, recommendations to perform diagnosis on any other covariance function different from those implemented in this study have been provided (Sections 4.2 and 4.7).

\item Explanations of how to estimate the number of basis functions needed for an accurate approximation for any other covariance function have also been provided (Section 4.7).

\item In the first submission of the paper, a linear representation for a periodic squared exponential kernel and the corresponding diagnosis analysis were presented in Appendix B. 

\item We have derived the numerical equations governing the relationships between the parameters of this linear representation of the periodic kernel. These equations have been included in the main text in Section 4.4.

\item We have applied the diagnostic tool on cases studies in Section 5. In that way, case studies in Section 5 have become more focused on the main goals of the paper, which are to facilitate the implementation of the method for practical users providing clear formulation of the method and provide a safety and general diagnostic tool to fit and diagnose the model.

\item We have added a new case study to Section 5 which consists in a wiggly 2D simulated data set. We have applied the diagnostic procedure on it. Even though the diagnostic was built for unidimensional kernels, we demonstrate its applicability and usefulness in multidimensional cases by diagnosing individually the different dimensions in each iteration. It allows finding the  optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases.

We have included in this new case study a brief discussion and presentation of additional results concerning computational cost in 2D, 3D and 4D, from case studies initially included in the online material.

{\color{blue} (Gabriel: I've not done this yet, but I could do it before the deadline.)}

\item We have added Section 4.8 where a discussion of the performance of the model in multidimensional cases are presented. 

\item We have emphasized in the paper that applying the diagnostic tool allows for minimum computational requirements that can be essential for very large data sets, multi-dimensional cases, or other problems that require repeated fitting such as cross-validation and simulation based calibration (Section 4.8).

\item A potential fitting overestimating effect when using too many basis functions relative to the wigglyness of the function to be learned has been commented. 

{\color{blue} (Gabriel: Currently we just have outlined but not discussed this. If we had time, it would be nice to discover why this overestimating effect is happening.)}

\item We expect this paper having a high impact on users as it is highly recommended to make the method usable in practice and in broad scenarios like uni-dimensional, multi(low)-dimensional functions and other problems that require repeated fitting.

\end{itemize}

\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

\subsection*{Reviewer \#1}

Authors are really grateful to the reviewer for their valuable comments which have been very helpful to improve the paper.

\subsubsection*{R\#1 Comment \#1}

\textbf{The authors correctly identify that for practical use in probabilistic programming environments the method has to be reliable and automatic enough, justifying the more detailed analysis of its parameters to identify when the approximation can be trusted. In addition, they provide the required implementations for one PP environment (Stan), although this is done at the level of case studies rather than integrating the approximation more tightly as part of a probabilistic programming environment.}

The Hilbert space approximation for GPs (HSGP) is presented as a general formulation for probabilistic modeling, so it can be implemented in different probabilistic programming frameworks, such as Stan, WinBugs, etc. The case study's models have also been formulated in general probabilistic language in the main manuscript, and Stan's implementations have also been provided as examples. Furthermore, HSGP model has been implemented in the \textit{brms} R-package that uses Stan to make model inference.

We are planning to implement the diagnostic tool which consists in iterative steps to fit and diagnose the model in the \textit{brms} R-package.
 
%This diagnostic iterative procedure is fundamentally based on a diagnostic rule to check whether the approximation is accurate and numerical equations allowing updating the key parameters of the method.

\subsubsection*{R\#1 Comment \#2}

\textbf{The analysis is reasonable and provides tangible results on how the approximation scheme should be used, but does not go very deep. There are not new theoretical results but instead the analysis is purely empirical and in fact a standard study where each approximation parameter is varied at a time to identify the limits when the approximation starts to fail. The analysis is properly carried out and results in a practical diagnostic, but did not require notable scientific insight.}

The performance of the HSGP model drastically depends on some setting parameters. The study pursues accurately measuring the sensitivity of the HSGP model to the values of these parameters, detecting when the approximation fails and when the parameter values are optimal in accuracy and computation cost. Ultimately, the aim of the study is to provide a diagnostic to check whether the approximation is sufficiently accurate, provide numerical equations to update the setting parameters if the approximation is not sufficiently accurate, and finally provide a safety and general procedure based on iterative steps to successfully fit the model, finding out optimal values for the setting parameters which allow for minimum computational requirements.

A theoretical approach to the diagnostic equations and rules is too complex that makes it not practical. The way to approach this is empirically. Making the empirical analysis we fully recognize the behavior of the approximation according to the parameters values, derive numerical equations gathering the relationships between the parameters that allow for updating the parameters and diagnosing the fitting.

Furthermore, by following our recommended diagnostic procedure, an optimum solution with minimum computational requirements is achieved, that can be essential in repeated fitting (e.g., in cross-validation or simulation based calibration), uni-dimensional cases with very large data sets, multi(low)-dimensional cases, even with small data sets, since knowing the optimum values for the setting parameters for each individual dimension can significantly reduce the computational requirements, otherwise fitting HSGPs would be unfeasible here.

\subsubsection*{R\#1 Comment \#3}

\textbf{The results are intuitive, but the process of determining the parameters in practice remains somewhat cumbersome as one needs to inspect the curves in Figures 6 and 7 to make the decision and there are no definite guidelines on how to modify the parameters when observing insufficient accuracy (e.g. no hints on how much one should increase m).}

We have derived numerical equations that gather the relationships between the key parameters of the model (initially presented in form of a graph in Figure 6) which allow updating the parameters and checking whether the approximation is accurate. We have also elaborated a safety and general procedure based on iterative steps to fit the model with definite rules to update the parameters and make diagnosis.

\subsubsection*{R\#1 Comment \#4}

\textbf{Furthermore, to use the approximation with any other kernel besides square exponential or Matérn one would essentially need to repeat the same analysis from scratch. This limits the value in probabilistic programming context. The authors indicate existing GP  libraries are limited and favour Stan for its generality, but since we now only have support for two specific kernels one could easily argue this approach is limited as well.}

We have implemented the HSGP model and the diagnostic tool for four different kernels, the squared exponential, Matern-3/2, Matern-5/2, and periodic squared exponential kernels, which cover a broad range of learning functions in practical applications. Kernel combinations that satisfy the requirements can also be used. We have also given recommendations in Section 4.2 and 4.7 to update $m$ and $c$ and perform diagnosis on any other different stationary kernel from those implemented in our study.

The study deeply describes in Section 3 the formulation and implementation of the HSGP model, description that can be used to implement it for any other different stationary kernel. The only new thing that the user needs to compute is the Fourier transform of the kernel to obtain the spectral density of the kernel.

\subsubsection*{R\#1 Comment \#5}

\textbf{it still feels like many educated practitioners would have found similar values for m and c by following a conventional validation procedure of applying the approximation with range of values for both on some example functions. While they would probably have ended up using slightly too large m or might spend a bit more computation while finding the best values, the practical difference might not be that big.}

Speculation from the reviewers side; we do not really know the expertise of our users. 

Rerunning takes computer and human time and we reduce that time by reducing the number of iterations and the computational requirements for each iteration. 

Not all practitioners may be educated enough to come up with and adjust procedures themselves. So clear, justified guidelines (that we provide) will be helpful and even required for the method to be used for many users.

Apart from the number of basis function, the boundary factor $c$ plays a crucial role here and has to be set carefully as a function of the wigglyness (true length-scale) of the function to be learned. By following our diagnostic rules and equations, both $m$ and $c$ can be set and properly updated with minimal effort.

An optimum solution with minimum computational requirements can be achieved following our recommended diagnostic procedure, otherwise it would be difficult. As discussed in the paper and above in this letter, using optimal values for the key parameters that allow for minimum computational requirements can be essential for very large data sets, multi-dimensional cases, or other problems that require repeated fitting.

\subsubsection*{R\#1 Comment \#6}

\textbf{The case studies are interesting and demonstrate the approximation scheme works in practice for simple statistical models while providing clear example codes, but they could be more focused towards the main goal of the paper.}

The developed diagnostic tool and iterative steps to fit and perform diagnosis on the HSGP model have been made prominent in the case studies.

The HSGP model is a new and computationally efficient representation of a GP. GPs are not simple statistical models. Improving the computational efficiency of a GP favors its implementation as modular components in flexible and complex modeling. In this sense, case study II and IV are examples of the use of the model in these flexible and complex modeling scenarios.

\begin{itemize}
\item Case study II involves a function that is composed of three additive GP components with different kernels, squared exponential and periodic kernels. Additionally this case study has a large data set of more than 7000 observations which would be unfeasible to be fitted using the exact GP model.

\item Case study IV (Leukemia data set) is a 4D function with a multilevel GP structure. This case study is also a good example that by using our diagnostic tool you can easily get an optimal solution in 4D which makes it significantly faster than regular GPs. Otherwise, user would had probably been struggling searching for useful values for the parameters without any guide.
\end{itemize}

The only limitation of the method is the number of dimensions as these affect computation through the total number of the basis functions needed. But this does not necessarily means a statistical model being simple.
In fact due to this high dependency of the computational requirements of the method on the number of basis functions, the analysis and diagnosis tool developed in this paper arises to be essential for practical applications and in broad scenarios.

\begin{itemize}
\item Case study I involves a wiggly function with a Mat\'ern-3/2 kernel. 

\item Case study III involves a two-dimensional function on which we use the diagnostic tool to fit the model. We show that, although the diagnostic tool was built for unidimensional covariance functions, it can be successfully used for multi-dimensional cases by diagnosing individually the different dimensions in each iteration. It allows gradually finding the optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases. 

Taking advantage of this case study we present additional insights about the performance of the method in 3D and 4D cases from other examples initially included in online material.

{\color{red} (Gabriel: I've not done this yet, but I could do it before the deadline.)}
\end{itemize}

\subsubsection*{R\#1 Comment \#7}

\textbf{Section 5.1 takes approximately four full pages to present results for a simple artificial data. It describes one concrete example of setting the parameters (that remains somewhat vague -- "In the first iteration, we choose...", "In the second iteration, m is increased to..."), but the detailed comparisons against splines could have been much more brief in a paper focusing on how to make the approximation easier to use in practice.}

We have simplified the section significantly but keeping references to equations in the main text of how to implement the approximation function. We have used the diagnosis tool and iterative steps to fit and perform diagnosis on the models. We have also improved the readability of the section.

\subsubsection*{R\#1 Comment \#8}

\textbf{Section 5.2 is similarly a bit besides the point -- the example model is interesting but regarding the choice of the parameters you simply say "We use m=30 basis functions and a boundary factor c=1.5" followed by stating that the length-scale estimate is good. This is what we would expect to see in a paper that later uses the method, but for a paper that is introducing the diagnostic I would expect more details and e.g. explanations of what would happen if the parameters were poorly chosen. I understand fully that verbally describing an iterative process is difficult, but was still a bit let down by these case studies.}

This case study involves an underlying function that is composed of three additive GP functions with different kernels, squared exponential and a periodic kernels. We have applied the diagnostic tool, describing the iterative steps to fit this model and performing diagnosis on the three additive GP components at the same time. This example also serves as an example of how useful our diagnosis can be in large 1D data sets.

\subsubsection*{R\#1 Comment \#9}

\textbf{Section 5.3 presents a multivariate case and seems to mostly provide a negative result on applicability of HSGP for multivariate cases. This is fine as the method is valuable even if limited to low dimensions, but it would have been more interesting to see a more detailed analysis of the intermediate region, especially D=2 and D=3 that are frequent in spatial and spatiotemporal analysis problems -- a practitioner would appreciate clear guidelines on when to use HSGP and how to recognise when it is not a good solution.}

It is difficult to give clear guidelines of when the application of the HSGP model can result to be impractical, basically because it ultimately depends on the wigglyness of the function to be learned which is, in most of the cases, unknown. In fact, for that reason the use of our diagnosis tool can be essential because it allows iteratively to fit the model using minimum computational requirements in each iteration. Observing how the requirements change in each iteration can be useful for the user to be able to recognize when the approximation is unfeasible to be applied.

We disagree with the reviewer that the HSGP performs poorer than the exact GP on this Leukemia data set. In fact using the diagnostic tool the user will discover easily the optimal values for $c$ and $m$ that allows for a significantly faster performance than using the exact GP. Without the guide of the diagnostic tool the user probably would had made several trials until finding out an accurate and practical solution, consuming a lot of requirements in this demanding 4D case.

The statement "its applicability to multidimensional cases is mostly negative" is inaccurate, as it ultimately depends on the wigglyness of the function.

As commented across the paper and in particular in Section 4.8, the method is limited in practice to the number of dimensions and the wigglyness of the function across the different dimensions. We have observed that it can be useful for $D<5$ conditioned to the wigglyness of the function. However, for $D=2$ it is still useful and significantly faster than the exact GP even for very wiggly functions. In Section 4.8 we give brief details on the performance of the model in multi-D cases found from various case studies carried out by the authors and initially presented in the online material. In this sense, the use of our recommended diagnostic allows to find the optimal values for $c$ and $m$ which allows for minimum computational requirements which can be essential on these multidimensional cases.

We have added a new case study to Section 5 which consists in a wiggly 2D simulated data set. We have applied the diagnostic procedure on it. Even though the diagnostic was built for unidimensional kernels, we demonstrate its applicability and usefulness in multidimensional cases by diagnosing individually the different dimensions in each iteration. It allows finding the  optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases. We have included in this new case study a brief discussion and presentation of additional results concerning computational cost in 2D, 3D and 4D, from case studies initially included in the online material. {\color{red} (Gabriel: I've not done this yet, but I could do it before the deadline.)}

\subsubsection*{R\#1 Comment \#10}

\textbf{Overall, I believe the paper has clear value for practical use and is worth publishing in some form: It provides nice code examples for HSGP via case studies and an iterative procedure for diagnosing when the approximation accuracy is good enough. However, the scientific novelty of the work is fairly limited and perhaps insufficient for publication in a top venue, in particular because there are no claims or contributions that would extend beyond this specific approximation scheme. There are also no clear scientific insights in the process itself, since the analysis is purely empirical and follows a straightforward protocol. In summary, the manuscript is a borderline case even if addressing the remarks below.}

This work is necessary to facilitate the implementation of the method for practical users, while Solin and Sarka (2020) fundamentally focus on the mathematical development of the model. We also analyze how the key factors of the model relate each other for accurate approximations. We derive numerical functions for these relationships that allow to update the parameters, perform diagnosis, and provide clear and useful guidelines for the whole procedure. So, we make it manageable for practical users, otherwise the practical applicability of the method would be highly limited.

We expect this paper to have a high impact on users as it is highly recommended to make the method usable in practice and in broad scenarios like uni-dimensional functions, multi-dimensional functions, and other problems that require repeated fitting such as cross-validation and simulation based calibration.

We do not see a problem in a purely simulative approach. It simply has different advantages and disadvantages over analytic approaches. In fact, as mentioned above, this study can only be approached from an empirical point of view. We would disagree on the scientific novelty (not all scientific novelty is mathematical in this regard). And we agree with the reviewer about the practical usefulness, which was our goal.

\subsubsection*{R\#1 Major revisions \#1}

\textbf{\#1.1 - The diagnostic involves comparing the estimated length-scale $\hat l$ against a minimum $l^*$ determined by m and c. I have trouble understanding the full validity of this process. I agree with your statement on page 8 about $\hat l$ being accurate if the approximation is accurate, but you do not state anything definite about the quality of $\hat l$ when the approximation is inaccurate. However, the process seems to implicitly assume we can still rely on $\hat l$ even then, with very relaxed justification ("If $\hat l$ does not exceed ... the approximation *may* be inaccurate"). Am I correct that your method would fail to diagnose a bad approximation if $\hat l$ was overestimated? I would like to see this discussion extended, at least by explicitly mentioning possible failure modes.}

An inaccurate approximation implies that number of basis functions $m$ is not enough and/or the boundary factor $c$ is not adequate.

We can not state anything definite about the estimated lengthscale $\hat{\ell}$ when the approximation is inaccurate, basically because it might ultimately depend on the specific frequency patterns of the signal/function to be learned, and also because $c$ must have been properly set. Although, we can state that for most of the cases, if $c$ is large enough, $\hat{\ell}$ will be below that minimum supported length-scale ($\ell^*$) determined by $m$ and $c$. But, as said before, it can not be generalized to all case studies because it might depend on the particular frequency patterns of a signal. Future research will be focused on investigating potential signals with particular frequency patterns that could escape from this rule.

What we can definitely state, which is in fact what our diagnosis is based on, is the following:

\begin{enumerate}
\item  Observing an $\hat{\ell}$ smaller than $\ell^*$ (i.e. $\hat{\ell}$ is overestimated), and $c$ is large enough given $\ell^*$, indicates a potential problem with the approximation. This happens because in inaccurate approximation scenarios the true length-scale is smaller than $\ell^*$, so $\hat{\ell}$ will tend to be towards smaller values than $\ell^*$.

\item The other way around, that is, observing $\hat{\ell}$ larger than $\ell^*$ (i.e. $\hat{\ell}$ is underestimated), the approximation is assumed to be accurate because when the true length-scale is larger than $\ell^*$, $\hat{\ell}$ will tend to be larger than $\ell^*$. However, we do not still have full evidence that this can be generalized to all possible cases as explained above (but, we can state that this rule can be apply for most of the the practical cases). For that reason, in order to make the diagnostic fully safety we recommend re-running the model, updating parameters, until seeing predictive accuracy measures, such as RMSE, $R^2$ and ELPD, do not improve.

As largely demonstrated in the paper in Section 4.6 and Case studies, these diagnostic rules leads to a safety, useful and fast iterative procedure to fit the models with minimum computational requirements.

These arguments have been included in the paper in Section 4.5. 
\end{enumerate} 

\textbf{\#1.2 - To me it seems Fig 5 (left) already hints that you tend to underestimate l when using bad approximation and the procedure may be valid in practice, but this is not transparent in the paper.}

For all cases showing inaccurate approximation in Fig. 5 (left), $\hat{\ell}$ is below $\ell^*$, as long as $c$ is large enough given $\ell^*$. It can be checked by computing $\ell^*$ for each case in Fig. 5 (left) by using equation (18). Following we show a few of these inaccurate cases in Fig. 5 (left), showing diagnostic $\hat{\ell} < \ell^*$ can be trusted to diagnose a bad approximation, as long as $c$ is large enough given $\ell^*$:

\begin{table}[h]
\centering
\begin{tabular}{ c c c c c c }
$m$ & $c$ & $\ell^*$ & $\hat{\ell}$ & \\ 
\hline \\[-4mm]
7  & 4   & 1.00 & $0.46$ & $\to$ & $\hat{\ell} < \ell^*$ \\
15 & 4   & 0.46 & $0.25$ & $\to$ & $\hat{\ell} < \ell^*$ \\
5  & 1.5 & 0.53 & $0.45$ & $\to$ & $\hat{\ell} < \ell^*$ \\
7  & 1.5 & 0.38 & $0.27$ & $\to$ & $\hat{\ell} < \ell^*$ \\
10 & 2.5 & 0.44 & $0.25$ & $\to$ & $\hat{\ell} < \ell^*$ \\
7  & 2   & 0.50 & $0.28$ & $\to$ & $\hat{\ell} < \ell^*$ \\
15 & 3   & 0.35 & $0.28$ & $\to$ & $\hat{\ell} < \ell^*$ \\
7  & 1.2 & 0.30 & $0.25$ & $\to$ & $\hat{\ell} < \ell^*$ \\
\end{tabular}
\end{table}

However, when $c$ is not large enough given $\ell^*$, $\hat{\ell}$ can be larger than $\ell^*$ and the approximation being inaccurate, so the diagnosis will fail in this case, for example:

\begin{table}[h]
\centering
\begin{tabular}{ c c c c c c }
$m$ & $c$ & $\ell^*$ & $\hat{\ell}$ & \\ 
\hline \\[-4mm]
20 & 1.1 & 0.10 & $0.17$ & $\to$ & $\hat{\ell} > \ell^*$ \\
10 & 1.1 & 0.19 & $0.20$ & $\to$ & $\hat{\ell} > \ell^*$ \\
\end{tabular}
\end{table}

It shows that it is essential to follow our diagnosis tool to be sure we are using valid values in each iterative step.

\textbf{\#1.3 - Do we have a reason for the error to be always towards understimating the lengthscale? Could this be proven?}

See response in \#1.1 above.


\subsubsection*{R\#1 Major revisions \#2}

\textbf{The process involves checking Figure 6 (or 7) for verifying whether the approximation is valid. This feels cumbersome in practice, and for better PP integration I would expect proper software support for this. It would be nice to at least outline how this could work, but even better to provide an actual tool. Both a visual tool plotting the current estimate as in Fig 13 and a textual feedback like "$\hat l$ is too small, you should either increase m or decrease c a bit -- we recommend the former" could work. One could also make this completely automatic, a loop that keeps on modifying the parameters until the threshold is reached. I would like you to discuss which of these options you would prefer and why.}

We have developed and presented a diagnostic procedure that consists in iterative steps to fit and diagnose the model. Numerical equations are used to set initial values and update the key parameters in each iterative step. The recommended diagnostic procedure is a safety and extensive procedure that allows to automatize the applicability of the method. See details in Section 4.5 and examples in Section 4.6, Case studies and Appendix C.

\subsubsection*{R\#1 Major revisions \#3}

\textbf{The paper is in general well written, but the structure could be improved. I think the specific diagnostic is now lost in the middle of the story in Sections 4 and 5 and would benefit from clear presentation in dedicated section (that would also be a good place to discuss the software support; see comment 2 above). The writing of both Sections 4 and 5 is also quite verbose and text-heavy, which makes reading the paper somewhat tedious. Section 4.1 is 200+ lines of text with no structure and as mentioned above both 5.1 and 5.2 are somewhat long compared to their value. Since you anyway provide exact code and re-use models from previous papers, you could compress the general discussion of the models and focus more on the process of determining the approximation parameters.}

Section 4 have been re-structured and updated by adding new subsections, such as a specific section on the theoretical evidence of near linear proportionality among the key parameters of the model, another section with the experimentation and resulting numerical diagnostic equations, another section supporting, detailing and discussing on the diagnostic rules, and another analyzing the performance of the diagnostic tool. Additionally, new subsections regarding how to proceed with other different kernels from those implemented in this study and some insights on how the method performs in multi-dimensional cases have also been added.

We have simplified and improved significantly the writing of Section 5. We have also focused the case studies more on the main goals of the paper:
\begin{enumerate}
\item Facilitate the implementation of the method for practical users providing clear formulation of the method.
\item Provide a safety and general diagnostic tool to fit and diagnose the model.
\end{enumerate}
 

\subsubsection*{R\#1 Major revisions \#4}

\textbf{It would be really interesting to see a bit more about how HSGP works for functions with 2-3 inputs, and in particular about how a practitioner can recognise whether it makes sense to use HSGP for their case or not. To me it seems clear HSGP is very often a reasonable method for D=1 and almost certainly breaks down for D>=5 or so unless working with very smooth functions (and for them almost any approximation works well), but clear diagnostics for quickly determining whether it could work for D=2 or D=3 would increase the contribution notably. Now the practical process would be to try it out and keep on increasing m until it starts working or one notices the computation is too slow, which feels wasteful -- as a practitioner I would rather just skip HSGP completely if finding out it does not help takes longer than solving the problem without the approximation.}

Diagnostic has been build for GPs with unidimensional covariance functions. Future research will focus on building analytical models that provide the diagnostics in multi-dimensional cases. However, as an approximation, we can use the diagnostic for unidimensional functions to make diagnosis individually on the different dimensions of a multidimensional GP model. 

See comment \#9 above for an extended answer.

\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

\subsection*{Reviewer \#2}

\subsubsection*{R\#2 Comment \#1}

\textbf{The paper gives experimental results for the method of Solin and Sarkka  (2020). Overall the idea such experiments is interesting, but the actual experiments are not extensive enough given the pure applied nature of this work.}

From the experiments, we have built numerical functions that characterize the relationships between the key parameters of the model which are the basis to perform diagnosis on the fitting. We have developed a diagnostic procedure to fit, diagnose and update parameters, based on iterative steps until an accurate solution is reached. Furthermore, this diagnostic tool provides the optimal values for the key parameters of the model that allow for minimizing the computational cost, which can be essential for very large data sets, multi-dimensional cases, or other problems that require repeated fitting such as cross-validation and simulated based calibration.

The diagnostic rules, the numerical functions that allow updating the parameters and the recommended iterative steps to fit and diagnose the model are extensive to the community and essential to make the model usable for practitioners.

All of this have been properly explained along Section 4 in the paper.

\subsubsection*{R\#2 Comment \#2}

\textbf{Experiments are mainly low dimensional (all 1D except a single 4D example). Please discuss high dimensional cases ; indeed equation 8 suggests poor scaling in dimension. Can it be applied to high dimensional data?.} 

We have mention in the paper how dimensionality affects the expected number of basis functions needed and that the effect of dimensionality is only through this. 

It is difficult to give clear guidelines of when the application of the HSGP model can result to be impractical, basically because it ultimately depends on the wigglyness of the function to be learned which is, in most of the cases, unknown. In fact, for that reason the use of our diagnosis tool can be essential because it allows iteratively to fit the model using minimum computational requirements in each iteration. Observing how the requirements change in each iteration can be useful for the user to be able to recognize when the approximation is unfeasible to be applied.

The Leukemia data set case study is a 4D data set. We have applied applied the diagnostic tool on it and we have been able to easily discover the optimal values for $c$ and $m$ that allows for a significantly faster performance than using the exact GP. Without the guide of the diagnostic tool the user probably would had made several trials until finding out an accurate and practical solution, consuming a lot of requirements in this demanding 4D case.

We have added a new case study to Section 5 which consists in a wiggly 2D simulated data set. We have applied the diagnostic procedure on it. Even though the diagnostic was built for unidimensional kernels, we demonstrate its applicability and usefulness in multidimensional cases by diagnosing individually the different dimensions in each iteration. It allows finding the  optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases. We have included in this new case study a brief discussion and presentation of additional results concerning computational cost in 2D, 3D and 4D, from case studies initially included in the online material. {\color{blue} (Gabriel: I've not done this yet, but I could do it before the deadline.)}

As commented across the paper and in particular in Section 4.8, the method is limited in practice to the number of dimensions and the wigglyness of the function across the different dimensions. We have observed that it can be useful for $D<5$ conditioned to the wigglyness of the function. However, for $D=2$ it is still useful and significantly faster than the exact GP even for very wiggly functions. In Section 4.8 we give brief details on the performance of the model in multi-D cases found from various case studies carried out by the authors and initially presented in the online material. In this sense, the use of our recommended diagnostic allows to find the optimal values for $c$ and $m$ which allows for minimum computational requirements which can be essential on these multidimensional cases.

\subsubsection*{R\#2 Comment \#3}

\textbf{There is no comparison with other techniques (except a spline method) ! Please compare with, e.g. "MCMC for Variationally Sparse Gaussian Processes" ; although this is SVI, it appears directly applicable for the problems considered here. Please also compare with non MCMC variational methods - while not directly applicable to generic MCMC methods, these are the sttandard and it would be nice to see how they compare in runtime.}

Aki: R2 is not happy that we compare only to splines and suggests we should compare to SVI and other variational methods like splines and VI would belong to the same category. We can use Stan's ADVI to run variational inference results. We should include a model for which usual variational inducing point approaches are not directly applicable due to non-exponential family model or combination of different components so that we can argue that we we stick to comparing to black box VI. We have recently run ADVI and improved robust ADVI results for birthday and motorcycle examples (the latter has latent GP for both location and log sigma)
and VI is not that good (it's annoying how common belief it is that black box
VI would be great).

\subsubsection*{R\#2 Comment \#4}

\textbf{On the eigenfunction expansion: 1) note that this is very similar to the Mercer expansion of e.g. Walder et al, "Fast Bayesian Intensity Estimation for the Permanental Process". 2) the Nystrom method also yields an approximate eigen expansion which has pros and cons to the method of the submission. For example, the Nystrom applies to any kernel (not just stationary) and yields a linear GP approximation, but requires some overhead for the setup. Given this submission is purely experimental, it would be nice to see comparisons.} 

Aki: R2 asks comparisons to Nystrom, but that comparison was
already made by Solin and Särkkä so I don't think we should add that.


%\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

%\nobibliography{references}


\end{document}


