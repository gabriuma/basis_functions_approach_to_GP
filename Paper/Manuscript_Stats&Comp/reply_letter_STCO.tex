
\documentclass[11pt]{report}
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{microtype}
\usepackage{lscape}

\usepackage[textwidth=17cm, textheight=21.2cm]{geometry}

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\usepackage{epstopdf}

\usepackage[sectionbib,numbers,sort&compress]{natbib}

\usepackage{subfigure}
\usepackage{multirow}
\usepackage{float}
\usepackage{soul}
\usepackage{xcolor}
%\graphicspath{{./images/}}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bm}

\usepackage{appendix}

\bibpunct[, ]{[}{]}{,}{}{,}{,}
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}

\setlength{\parskip}{0.5em}
\renewcommand{\baselinestretch}{1.1}

\renewcommand{\bibname}{References}

\usepackage{dashrule}

\usepackage{bibentry}
\bibliographystyle{apalike}

\makeatletter 
\renewcommand\BR@b@bibitem[2][]{\BR@bibitem[#1]{#2}\BR@c@bibitem{#2}}           
\makeatother

\nobibliography*

\begin{document}


We would like to thank the reviewers for their thorough comments and valuable feedback, which has helped us a lot in improving the paper. First, a summary of the improvements, changes, and new insights achieved during the revision are outlined. Then, all comments are addressed in a point-by-point manner, with separate replies to each reviewer. 
Throughout, comments of the reviewers are hightlighted in bold.

\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

\subsection*{Summary of the updates and insights}

\textit{General updates:}

\begin{itemize}

\item We have improved the paper significantly, including new insights from new experiments and analysis. The readability of Sections 4 and 5 have also been improved. 

\item A safe, general, and extensive procedure that allows us to diagnose and automatize the fitting process has been defined explicitly (Section 4). 

\item Examples in Section 5 have been clarified.

\item The analysis has been extended to the Mat\'ern-5/2 kernel. So the whole study provides the explicit diagnostic for a squared exponential, Mat\'ern-3/2, Mat\'ern-5/2 (Sections 4.3 and 4.3.1), and periodic squared exponential (Sections 3.3, 4.4 and Appendix C) covariance functions. In addition connection to other covariance functions is discussed.

\item A discussion of the performance of the model and the applicability of the diagnostic tool in multidimensional cases have been included in Section 4.8 and Case study III.

%Paul: I don't see how this is an update of the paper
%\item We expect this paper having a high impact on users as it is highly recommended to make the method usable in practice and in broad scenarios.

\end{itemize}

\noindent \textit{Specific updates:}

\begin{itemize}

\item A discussion about the theoretical evidence of the near linear proportionality between the hyperparameters of the model has been added (Section 4.2). 

\item We have derived numerical equations that characterize the relationships between the hyperparameters of the model for each particular kernel, which are useful to update and find out optimal values for the hyper-parameters (Section 4.3.1). 

\item The main diagnostic rule that indicates whether the approximation may be sufficiently accurate has been further discussed regarding its reliability and practial applicability (Section 4.5).

\item A diagnostic procedure based on iterative steps to fit and diagnose the approximation has been proposed (Section 4.5.1 and Section 4.6), which is based on: 1) recommendations to set initial values for the hyperparameters, 2) diagnostic to check if the approximation is sufficiently accurate (Sections 4.5), and 3) numerical equations to automatize updating the parameters in the fitting process (Sections 4.3.1).

\item Recommendations to perform diagnostics on any other covariance function different from those discussed in this study have been provided (Sections 4.2 and 4.7).

\item We have added a new case study to Section 5 which consists of a wiggly 2D simulated data set, demonstrating the applicability and usefulness of the diagnostic tool in multidimensional cases. Additional results concerning computational cost in 2D, 3D and 4D have been presented and briefly discussed, emphasizing that applying the diagnostic tool allows for minimum computational requirements that can be essential for very large data sets, multi-dimensional cases, or other problems that require repeated fitting.

\end{itemize}

\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

\subsection*{Reviewer \#1}

We are grateful for your valuable comments and suggestions, which have been very helpful to improve the paper, and more generally for your time you have dedicated to reviewing it.

\subsubsection*{R\#1 Comment \#1}

\textbf{The authors correctly identify that for practical use in probabilistic programming environments the method has to be reliable and automatic enough, justifying the more detailed analysis of its parameters to identify when the approximation can be trusted. In addition, they provide the required implementations for one PP environment (Stan), although this is done at the level of case studies rather than integrating the approximation more tightly as part of a probabilistic programming environment.}

The Hilbert space approximation for GPs (HSGP) is presented as a general formulation for probabilistic modeling, so it can be implemented in different probabilistic programming frameworks, such as Stan, PyMC, Pyro, Beanmachine, etc. The case study's models have also been formulated in general probabilistic language in the main manuscript, and Stan's implementations have also been provided as examples. Furthermore, the HSGP model framework has been fully implemented in the \textit{brms} R-package that uses Stan as backend to make model inference.

% and we are planning to implement the diagnostic tool which consists in iterative steps to fit and diagnose the model also in the \textit{brms} R-package. 

%Paul: Not in the near future; highly unlikely before the paper is accepted
%{\color{blue}(Gabriel: Paul, do we intend to implement the diagnostic procedure in brms?)}
 
%This diagnostic iterative procedure is fundamentally based on a diagnostic rule to check whether the approximation is accurate and numerical equations allowing updating the key parameters of the method.

\subsubsection*{R\#1 Comment \#2}

\textbf{The analysis is reasonable and provides tangible results on how the approximation scheme should be used, but does not go very deep. There are not new theoretical results but instead the analysis is purely empirical and in fact a standard study where each approximation parameter is varied at a time to identify the limits when the approximation starts to fail. The analysis is properly carried out and results in a practical diagnostic, but did not require notable scientific insight.}

The performance of the HSGP model drastically depends on some hyperparameters. The study pursues accurately measuring the sensitivity of the HSGP model to the values of these parameters, detecting when the approximation fails and when the parameter values are optimal in accuracy and computation cost. Ultimately, the aim of the study is to provide: 1) a diagnostic to check whether the approximation is sufficiently accurate, 2) numerical equations to update the hyperparameters if the approximation is not sufficiently accurate, and 3) a safety and general procedure based on iterative steps to successfully fit the model, finding out optimal values for the hyperparameters which allow for minimum computational requirements.

While we agree that a theoretical approach has a lot of merit, we do not see how such a theoretical approach to the diagnostic equations and rules would have been feasible. Thus we have approached these challenges empirically via numerical experiments, instead. By means of this empirical analysis, we got a thorough understanding of the behavior of the approximation as a function of the hyperparameters, derive numerical equations that capture the relationships between these parameters, which allow for an iterative procedure to ensure sufficient accuracy of the approximation.

Furthermore, by following our recommended diagnostic procedure, an optimum solution with minimum computational requirements is achieved. This can be essential especially in cases where computation time is prohibitive, for example, when having to fit the model repeatedly (e.g., in cross-validation or simulation based calibration), uni-dimensional cases with very large data sets, or multi(low)-dimensional cases, even with small data sets. 

%since knowing the optimum values for the hyperparameters for each individual dimension can significantly reduce the computational requirements, otherwise fitting HSGPs would be unfeasible here.

\subsubsection*{R\#1 Comment \#3}

\textbf{The results are intuitive, but the process of determining the parameters in practice remains somewhat cumbersome as one needs to inspect the curves in Figures 6 and 7 to make the decision and there are no definite guidelines on how to modify the parameters when observing insufficient accuracy (e.g. no hints on how much one should increase m).}

We have derived numerical equations that gather the relationships between the key parameters of the model (initially presented in form of a graph in Figure 6) which allow updating the parameters and checking whether the approximation is accurate (Section 4.3.1). We have also added a general and robust iterative procedure to derive minimally sufficient hyperparameter values that ensure good GP approximations via our HSGP approach (Sections 4.5 and 4.6).

\subsubsection*{R\#1 Comment \#4}

\textbf{Furthermore, to use the approximation with any other kernel besides square exponential or Matérn one would essentially need to repeat the same analysis from scratch. This limits the value in probabilistic programming context. The authors indicate existing GP  libraries are limited and favour Stan for its generality, but since we now only have support for two specific kernels one could easily argue this approach is limited as well.}

We have implemented the HSGP model and the diagnostic tool for four different kernels, the squared exponential, Matern-3/2, Matern-5/2, and periodic squared exponential kernels, which cover a broad range of learning functions in practical applications (Sections 4.3 and 4.4). Kernel combinations that satisfy the requirements can also be used. We have also given recommendations to update $m$ and $c$ and perform diagnostics on any other different stationary kernel from those implemented in our study, by analyzing the constants characterizing the relationships for each covariance function (Sections 4.2 and 4.7). Explanations on how to estimate the number of basis functions needed for an accurate approximation for any other covariance function have also been provided (Section 4.7).

In Section 3, we describe the formulation and implementation of the HSGP model in detail, a description that can be used to implement it for any other stationary kernel if required. The only kernel-specific function that the user needs to know is the Fourier transform of the kernel to obtain its spectral density (Section 3 and Section 4.7).

\subsubsection*{R\#1 Comment \#5}

\textbf{it still feels like many educated practitioners would have found similar values for m and c by following a conventional validation procedure of applying the approximation with range of values for both on some example functions. While they would probably have ended up using slightly too large m or might spend a bit more computation while finding the best values, the practical difference might not be that big.}

Our experience tells us that the range of expertise in users of probabilistics programming languages such as Stan and their higher level interfaces such a brms is quite wide. We don't want to speculate on the percentage of users that would be able to come up with comparable solutions themselves. To study this empirically, one had to conduct extensive user studies and their are not in scope of this paper.
We want to highlight though that rerunning of models and deciding about good updating rules takes a lot of human and compute time. We substantially reduce that time by reducing the number of model iterations, the computational requirements for each iteration, as well as eliminating the time an educated practioners would have had to spend to come up with some sensible rule themselves.

%Not all practitioners may be educated enough to come up with and adjust procedures themselves. So clear, justified guidelines (that we provide) will be helpful and even required for the method to be used for many users.

%Apart from the number of basis function, the boundary factor $c$ plays a crucial role here and has to be set carefully as a function of the wigglyness (true length-scale) of the function to be learned, which is unknown a prior. By following our diagnostic rules and equations, both $m$ and $c$ can be set and properly updated with minimal effort.

%An optimum solution with minimum computational requirements can be achieved following our recommended diagnostic procedure, otherwise it would be difficult. As discussed in the paper and above in this letter, using optimal values for the key parameters that allow for minimum computational requirements can be essential for very large data sets, multi-dimensional cases, or other problems that require repeated fitting.

\subsubsection*{R\#1 Comment \#6}

\textbf{The case studies are interesting and demonstrate the approximation scheme works in practice for simple statistical models while providing clear example codes, but they could be more focused towards the main goal of the paper.}

The developed diagnostic tool and iterative steps to fit and perform diagnostics on the HSGP model have been made more prominent in the case studies, to better link them our main goals and the rest of the paper. In particular:

%The HSGP model is a new and computationally efficient representation of a GP. Improving the computational efficiency of a GP favors its implementation as modular components in flexible and complex modeling. In this sense, case study II and IV are examples of the use of the model in these flexible and complex modeling scenarios.

\begin{itemize}
%\item Case study I involves a wiggly function with a Mat\'ern-3/2 kernel.

\item Case study II involves a function that is composed of three additive GP components with different kernels, squared exponential and periodic kernels. Additionally this case study has a large data set of more than 7000 observations which would be unfeasible to be fitted using a regular formulation of the GP model.

\item Case study III involves 2D and 3D functions on which the diagnostic tool is used to fit and diagnose the model. We show that, although the diagnostic tool was built for unidimensional covariance functions, it can be successfully used for multi-dimensional cases by diagnosing individually the different dimensions in each iteration. It allows gradually finding the optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases. We have included in this new case study a brief discussion and presentation of additional results concerning computational cost in 2D, 3D and 4D cases.

\item Case study IV (Leukemia data set) is a 4D function with a multilevel GP structure. This case study is also a good example that by using our diagnostic tool you can easily get an optimal solution in 4D which makes it significantly faster than regular GPs. Otherwise, user would had probably been struggling searching for useful values for the hyperparameters without any guidance.
\end{itemize}

The only main limitation of the HSGP method is the expoential scaling of the computation with increasing number of input dimensions (assuming wigglines stays the same and the amount of data is sufficient to get sufficient information about that wiggliness). 
Due to the high dependency of the computational requirements of the method on the number of basis functions, the analysis and diagnostics tool developed in this paper arises to be essential for practical application in a wide range of scenarios. 

\subsubsection*{R\#1 Comment \#7}

\textbf{Section 5.1 takes approximately four full pages to present results for a simple artificial data. It describes one concrete example of setting the parameters (that remains somewhat vague -- "In the first iteration, we choose...", "In the second iteration, m is increased to..."), but the detailed comparisons against splines could have been much more brief in a paper focusing on how to make the approximation easier to use in practice.}

We have simplified the section significantly but keeping references to equations in the main text of how to implement the approximation function. We have used the diagnostic tools and iterative steps to fit and perform diagnostics on the models. We have also improved the readability of the section.

\subsubsection*{R\#1 Comment \#8}

\textbf{Section 5.2 is similarly a bit besides the point -- the example model is interesting but regarding the choice of the parameters you simply say "We use m=30 basis functions and a boundary factor c=1.5" followed by stating that the length-scale estimate is good. This is what we would expect to see in a paper that later uses the method, but for a paper that is introducing the diagnostic I would expect more details and e.g. explanations of what would happen if the parameters were poorly chosen. I understand fully that verbally describing an iterative process is difficult, but was still a bit let down by these case studies.}

Following your suggestions, we improve the case study to be better integrated with the rest of the paper. This case study involves an underlying function that is composed of three additive GP functions with different kernels, two squared exponential kernels and a periodic kernel. We have now applied the diagnostic tool, describing the iterative steps to fit this model and perform diagnostics on the three additive GP components at the same time. This case study also serves as an example of how useful our diagnostics can be in large data sets with 1D HSGPs.

\subsubsection*{R\#1 Comment \#9}

\textbf{Section 5.3 presents a multivariate case and seems to mostly provide a negative result on applicability of HSGP for multivariate cases. This is fine as the method is valuable even if limited to low dimensions, but it would have been more interesting to see a more detailed analysis of the intermediate region, especially D=2 and D=3 that are frequent in spatial and spatiotemporal analysis problems -- a practitioner would appreciate clear guidelines on when to use HSGP and how to recognise when it is not a good solution.}

The HSGP model is definitely useful in 1D and 2D, even for very wiggly functions, unless the number of data points is very small ($n \lesssim 300$) where the regular formulation of a GP is already reasonably fast itself.
It is difficult to give clear guidelines of when the application of the HSGP model can result to be impractical in other multidimensional cases, basically because it ultimately depends on the wigglyness of the function to be learned which is, in most of the cases, unknown. For that reason, in fact, the use of our diagnostics tool can be essential because it allows to iteratively fit the model using minimum computational requirements in each iteration. Observing how the requirements change in each iteration can be useful for the user to be able to recognize when the approximation is unfeasible to be applied. For $D>5$, even for very smooth functions, HSGPS definitely seem to be impractical. For $D<3$ it is widely useful and significantly faster than the exact GP even for very wiggly functions.

We disagree with the reviewer that the HSGP performs poorer than the exact GP on this Leukemia data set. In fact using the diagnostic tool the user will discover easily the optimal values for $c$ and $m$ that allows for a significantly faster performance than using the exact GP. Without the guide of the diagnostic tool, the user would have likely made several trials until finding an accurate and practical solution, consuming a lot of computation requirements in this highly demanding 4D case. Insofar, the understanding that "its applicability to multidimensional cases is mostly negative" is not fully accurate, as it ultimately depends on the wigglyness of the function. We now better discuss this point in various places in the paper. Specifically, in Section 4.8, we provide details on the performance of the model in multi-dimensional cases. 

%the method is limited in practice to the number of dimensions and the wigglyness of the function across the different dimensions. We have observed that it can be useful for $D<5$ depending on the wigglyness of the function. .

%In this sense, the use of our recommended diagnostic allows to find the optimal values for $c$ and $m$ which allows for minimum computational requirements which can be essential on these multidimensional cases.

We have also added a new case study to Section 5 which consists of wiggly 2D and 3D simulated data sets, where have applied the diagnostic procedure too. Even though the diagnostic was built for unidimensional kernels, we demonstrate its applicability and usefulness in multidimensional cases by diagnosing the different dimensions in each iteration individually. 
%It allows us to find the optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases.
In this new case study, we have also included a brief discussion and presentation of additional results concerning computational cost in 2D, 3D, and 4D.

\subsubsection*{R\#1 Comment \#10}

\textbf{Overall, I believe the paper has clear value for practical use and is worth publishing in some form: It provides nice code examples for HSGP via case studies and an iterative procedure for diagnosing when the approximation accuracy is good enough. However, the scientific novelty of the work is fairly limited and perhaps insufficient for publication in a top venue, in particular because there are no claims or contributions that would extend beyond this specific approximation scheme. There are also no clear scientific insights in the process itself, since the analysis is purely empirical and follows a straightforward protocol. In summary, the manuscript is a borderline case even if addressing the remarks below.}

Thank you again for your thorough review. To us, also empirical analysis provides scientific insights, in particular as we can study much more complicated scenarios that we cannot feasibly approach my mathematical analysis alone. As such, we think our paper nicely complements existing research.

Solin and Sarka (2020) fundamentally focus on the mathematical development of the model, while our work is necessary to facilitate the easier use of the method for practical users. We also analyze how the key factors of the model relate each other for accurate approximations. We derive numerical functions for these relationships that allow to update the parameters, perform diagnostics, and provide clear and useful guidelines for the whole procedure. So, we make it manageable for practical users, otherwise the practical applicability of the method would be highly limited.

We expect this paper to have a strong impact on how widely basis function GPs are used. Our contribution makes these approximate GPs more practically applicable for both uni-dimensional and multi-dimensional functions, even in combination with additional challenges that require repeated fitting such as cross-validation or simulation based calibration.

%We do not see a problem in a purely simulative approach. It simply has different advantages and disadvantages over analytic approaches. In fact, as mentioned above, this study can only be approached from an empirical point of view. We would disagree on the scientific novelty (not all scientific novelty is mathematical in this regard). And we agree with the reviewer about the practical usefulness, which was our goal.

\subsubsection*{R\#1 Major revisions \#1}

\textbf{\#1.1 - The diagnostic involves comparing the estimated length-scale $\hat l$ against a minimum $l^*$ determined by m and c. I have trouble understanding the full validity of this process. I agree with your statement on page 8 about $\hat l$ being accurate if the approximation is accurate, but you do not state anything definite about the quality of $\hat l$ when the approximation is inaccurate. However, the process seems to implicitly assume we can still rely on $\hat l$ even then, with very relaxed justification ("If $\hat l$ does not exceed ... the approximation *may* be inaccurate"). Am I correct that your method would fail to diagnose a bad approximation if $\hat l$ was overestimated? I would like to see this discussion extended, at least by explicitly mentioning possible failure modes.}

We have substantially extended the discussion around our proposed diagnostic. In short, an inaccurate approximation implies that the number of basis functions $m$ is not enough and/or the boundary factor $c$ is too small. Our experiments yield consistently that, if $c$ is large enough, $\hat{\ell}$ will be below that minimum supported length-scale ($\ell^*$) determined by $m$ and $c$; and observation on which our diagnostic procedure rests. We cannot rule out with certainty that and inaccurate approximation might also yield an $\hat{\ell}$ above the minimum supported length-scale ($\ell^*$), too. However, we have not encountered this case in our experiments.

As demonstrated in Section 4.6 and our case studies, our developed diagnostic rules leads to a reliable, useful, and fast iterative procedure to fit the models with minimum computational requirements. More arguments supporting this notion have been included in the paper in Section 4.5. 

%We cannot state anything definitive about the estimated lengthscale $\hat{\ell}$ when the approximation is inaccurate, basically because it might ultimately depend on the specific frequency patterns of the signal/function to be learned, and also because $c$ must be properly set. Although, we can state that for most of the cases, if $c$ is large enough, $\hat{\ell}$ will be below that minimum supported length-scale ($\ell^*$) determined by $m$ and $c$. But, as said before, it cannot be generalized to all case studies because it might depend on the particular frequency patterns of a signal. Future research will be focused on investigating potential signals with particular frequency patterns that could escape from this rule.

%What we can say more definitely is the following:

%\begin{enumerate}
%\item Observing an $\hat{\ell}$ smaller than $\ell^*$, for $c$ large enough given $\ell^*$, indicates a potential problem with the approximation. This happens because in such scenarios the true length-scale is smaller than $\ell^*$, so $\hat{\ell}$ will tend to take on values smaller than $\ell^*$.

%\item The other way around, that is, observing $\hat{\ell}$ larger than $\ell^*$, the approximation is assumed to be accurate because when the true length-scale is larger than $\ell^*$, $\hat{\ell}$ will tend to be larger than $\ell^*$. However, we do not still have full evidence that this can be generalized to all possible cases as explained above (but, we can state that this rule can be apply for most of the the practical cases). For that reason, in order to make the diagnostic fully safety we recommend re-running the model, updating parameters, until seeing predictive accuracy measures, such as RMSE, $R^2$ and ELPD, do not improve.

%\end{enumerate} 

\textbf{\#1.2 - To me it seems Fig 5 (left) already hints that you tend to underestimate l when using bad approximation and the procedure may be valid in practice, but this is not transparent in the paper.}

We agree and have made this observation and corresponding assumptions more explicit in the paper. Below, we detail some results corresponding to Figure 5 for your convenience.

For all cases showing inaccurate approximation in Fig. 5 (left), $\hat{\ell}$ is below $\ell^*$, as long as $c$ is large enough given $\ell^*$. It can be checked by computing $\ell^*$ for each case in Fig. 5 (left) by using equation (18). 

%Following we show a few of these inaccurate cases in Fig. 5 (left), showing diagnostic $\hat{\ell} < \ell^*$ can be trusted to diagnose a bad approximation, as long as $c$ is large enough given $\ell^*$:

\begin{table}[h]
\centering
\begin{tabular}{ c c c c c c }
$m$ & $c$ & $\ell^*$ & $\hat{\ell}$ & \\ 
\hline \\[-4mm]
7  & 4   & 1.00 & $0.46$ & $\to$ & $\hat{\ell} < \ell^*$ \\
15 & 4   & 0.46 & $0.25$ & $\to$ & $\hat{\ell} < \ell^*$ \\
5  & 1.5 & 0.53 & $0.45$ & $\to$ & $\hat{\ell} < \ell^*$ \\
7  & 1.5 & 0.38 & $0.27$ & $\to$ & $\hat{\ell} < \ell^*$ \\
10 & 2.5 & 0.44 & $0.25$ & $\to$ & $\hat{\ell} < \ell^*$ \\
7  & 2   & 0.50 & $0.28$ & $\to$ & $\hat{\ell} < \ell^*$ \\
15 & 3   & 0.35 & $0.28$ & $\to$ & $\hat{\ell} < \ell^*$ \\
7  & 1.2 & 0.30 & $0.25$ & $\to$ & $\hat{\ell} < \ell^*$ \\
\end{tabular}
\end{table}

However, when $c$ is not large enough given $\ell^*$, $\hat{\ell}$ can be larger than $\ell^*$ and the approximation being inaccurate, so the diagnostics will fail in this case, for example:

\begin{table}[h]
\centering
\begin{tabular}{ c c c c c c }
$m$ & $c$ & $\ell^*$ & $\hat{\ell}$ & \\ 
\hline \\[-4mm]
20 & 1.1 & 0.10 & $0.17$ & $\to$ & $\hat{\ell} > \ell^*$ \\
10 & 1.1 & 0.19 & $0.20$ & $\to$ & $\hat{\ell} > \ell^*$ \\
\end{tabular}
\end{table}

Together, this demonstrates that it is essential to follow our diagnostic procedure to ensure using valid values in each iterative step.

\textbf{\#1.3 - Do we have a reason for the error to be always towards understimating the lengthscale? Could this be proven?}

Yes. Please see our response to your comment \#1.1 above.


\subsubsection*{R\#1 Major revisions \#2}

\textbf{The process involves checking Figure 6 (or 7) for verifying whether the approximation is valid. This feels cumbersome in practice, and for better PP integration I would expect proper software support for this. It would be nice to at least outline how this could work, but even better to provide an actual tool. Both a visual tool plotting the current estimate as in Fig 13 and a textual feedback like "$\hat l$ is too small, you should either increase m or decrease c a bit -- we recommend the former" could work. One could also make this completely automatic, a loop that keeps on modifying the parameters until the threshold is reached. I would like you to discuss which of these options you would prefer and why.}

In response, we have developed and presented a diagnostic procedure that consists of iterative steps to fit and diagnose the model. Numerical equations are used to set initial values and update the key parameters in each iterative step. The recommended diagnostic procedure allows to automatize the application of the method. In the revised manuscript, please see Section 4.5 and examples in Section 4.6, Case studies, and Appendix C, for more details.

\subsubsection*{R\#1 Major revisions \#3}

\textbf{The paper is in general well written, but the structure could be improved. I think the specific diagnostic is now lost in the middle of the story in Sections 4 and 5 and would benefit from clear presentation in dedicated section (that would also be a good place to discuss the software support; see comment 2 above). The writing of both Sections 4 and 5 is also quite verbose and text-heavy, which makes reading the paper somewhat tedious. Section 4.1 is 200+ lines of text with no structure and as mentioned above both 5.1 and 5.2 are somewhat long compared to their value. Since you anyway provide exact code and re-use models from previous papers, you could compress the general discussion of the models and focus more on the process of determining the approximation parameters.}

Section 4 has been re-structured and updated by adding new subsections. In particular this includes, a subsection on the theoretical evidence of near linear proportionality among the key hyperparameters of the model, a subsection with the experimentation and resulting numerical diagnostic equations, a subsection supporting, detailing, and discussing on the diagnostic rules, and a subsection analyzing the performance of the diagnostic tool. Additionally, new subsections regarding how to proceed with other different kernels from those implemented in this study and some insights on how the method performs in multi-dimensional cases have been added.

We have simplified and significantly improved the writing in Section 5. We have also focused the case studies more on the main goals of the paper, which are: 1) to facilitate the implementation of the method for practical users providing clear a formulation of the method, and 2) and to provide an easy and general diagnostic tool to achieve good approximations via HSGPs.
 

\subsubsection*{R\#1 Major revisions \#4}

\textbf{It would be really interesting to see a bit more about how HSGP works for functions with 2-3 inputs, and in particular about how a practitioner can recognise whether it makes sense to use HSGP for their case or not. To me it seems clear HSGP is very often a reasonable method for D=1 and almost certainly breaks down for $D>=5$ or so unless working with very smooth functions (and for them almost any approximation works well), but clear diagnostics for quickly determining whether it could work for D=2 or D=3 would increase the contribution notably. Now the practical process would be to try it out and keep on increasing m until it starts working or one notices the computation is too slow, which feels wasteful -- as a practitioner I would rather just skip HSGP completely if finding out it does not help takes longer than solving the problem without the approximation.}

Our diagnostic has been build for GPs with unidimensional covariance functions. Future research will focus on building analytical models that provide the diagnostic for multi-dimensional cases, as well. However, for now, we can use the diagnostic for unidimensional functions and apply it to each dimensionan of a multidimensional GP model individually, which seems to works quite well in our examples. Please see comment \#9 above for an extended answer on this topic.

\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

\subsection*{Reviewer \#2}

We are grateful for your valuable comments and suggestions, which have been very helpful to improve the paper, and more generally for your time you have dedicated to reviewing it.

\subsubsection*{R\#2 Comment \#1}

\textbf{The paper gives experimental results for the method of Solin and Sarkka  (2020). Overall the idea such experiments is interesting, but the actual experiments are not extensive enough given the pure applied nature of this work.}

In the revised version of the paper, we have substantially extended the experiments. On that basis, we have derived equations that characterize the relationships between the key hyperparameters of the HSGP model and  the goodness of the corresponding exact GP approximation. We have developed a procedure to diagnose the appropriateness of the hyperparameters and to update them based on iterative steps until an accurate approximation has been achieved. Furthermore, this diagnostic tool provides optimal values for those hyperparameters with respect to minimizing the computational cost subject to sufficient accuracy of the approximation. Minimizing computation cost is particularily important for very large data sets, multi-dimensional cases, or other problems that require repeated fitting, such as cross-validation and simulated based calibration. All of this new content is discussed in detail in Section 4 of the paper.

%The diagnostic rules, the numerical functions that allow updating the parameters and the recommended iterative steps to fit and diagnose the model are extensive to the community and essential to make the model usable for practitioners.



\subsubsection*{R\#2 Comment \#2}

\textbf{Experiments are mainly low dimensional (all 1D except a single 4D example). Please discuss high dimensional cases ; indeed equation 8 suggests poor scaling in dimension. Can it be applied to high dimensional data?.} 

Indeed, the main limitation of the HSGP approach is its bad scaling with increasing number of input dimensions. In the revised version, we now make this more explicit and discuss the implications in detail, in particular in Section 4.8.

The HSGP model is definitely highly useful in 1D and 2D, even for very wiggly functions, unless the number of data points is very small ($n \lesssim 300$) where the regular formulation of a GP is already reasonably fast. It is difficult to give clear guidelines of when the application of the HSGP model becomes impractical in multidimensional cases, because it also depends on the wigglyness of the function to be learned which is, in most of the cases, unknown. For that reason, the use of our diagnostic tool is highly beneficial to minimize computational requirements in order to achieve a good approximation. Observing how the requirements change in each iteration can be useful for the user to be able to recognize when the approximation is unfeasible to be applied. For $D>5$, even for very smooth functions, HSGPs indeed seem to be impractical and we now state this explicitely.

In the Leukemia data set case study, we present a 4D HSGP model. We have applied the diagnostic tool and have been able to easily discover the optimal values for $c$ and $m$ that allows for a significantly faster performance than using the exact GP. Without the guidance of the diagnostic tool, a user would have to go through several more trials until finding a sufficiently accurate solution, which would result in substantially increased human and computer time requirements.

We have also added a new case study to Section 5 which consists of wiggly 2D and 3D simulated data sets, where have applied the diagnostic procedure too. Even though the diagnostic was built for unidimensional kernels, we demonstrate its applicability and usefulness in multidimensional cases by diagnosing the different dimensions in each iteration individually. 
%It allows us to find the optimal solution with the minimum requirements that can be essential to use the HSGP model in multidimensional cases.
In this new case study, we have also included a brief discussion and presentation of additional results concerning computational cost in 2D, 3D, and 4D.

%As commented across the paper and in particular in Section 4.8, the method is limited in practice to the number of dimensions and the wigglyness of the function across the different dimensions. We have observed that it can be useful for $D<5$ conditioned to the wigglyness of the function. However, for $D=2$ it is still useful and significantly faster than the exact GP even for very wiggly functions. In Section 4.8 we give brief details on the performance of the model in multi-D cases. In this sense, the use of our recommended diagnostic allows to find the optimal values for $c$ and $m$ which allows for minimum computational requirements which can be essential on these multidimensional cases.

\subsubsection*{R\#2 Comment \#3}

\textbf{There is no comparison with other techniques (except a spline method) ! Please compare with, e.g. "MCMC for Variationally Sparse Gaussian Processes" ; although this is SVI, it appears directly applicable for the problems considered here. Please also compare with non MCMC variational methods - while not directly applicable to generic MCMC methods, these are the standard and it would be nice to see how they compare in runtime.}

The main comparison that we focus on is the Hilbert space basis function approximation (our HSGP method) against the exact GP model. In all comparisons, the inference conditional on the model is assumed to be accurate. In other words, we compare the exact to an approximate model, using asymptotically correct inference. For this purpose, we have used efficient dynamic HMC, the MCMC convergence diagnostics did not reveal problems, and thus the accuracy of the inference itself can be considered good. 

While we agree that other comparisons could interesting as well, for example MCMC vs. variational inference, they would blow up the already extensive scope of the paper. Some comparisons of MCMC and variational inference for basis function GPs can be found in

Lu Zhang, Bob Carpenter, Andrew Gelman, and Aki Vehtari (2021). Pathfinder: Parallel quasi-Newton variational inference. arXiv preprint arXiv:2108.03782.

Further comparisons of the Hilbert space basis function approximations against other GP approximations are provided by Solin and Särkkä (2020), which is cited prominently in our paper.

% Aki: R2 is not happy that we compare only to splines and suggests we should compare to SVI and other variational methods like splines and VI would belong to the same category. We can use Stan's ADVI to run variational inference results. We should include a model for which usual variational inducing point approaches are not directly applicable due to non-exponential family model or combination of different components so that we can argue that we we stick to comparing to black box VI. We have recently run ADVI and improved robust ADVI results for birthday and motorcycle examples (the latter has latent GP for both location and log sigma)
% and VI is not that good (it's annoying how common belief it is that black box
% VI would be great).

\subsubsection*{R\#2 Comment \#4}

\textbf{On the eigenfunction expansion: 1) note that this is very similar to the Mercer expansion of e.g. Walder et al, "Fast Bayesian Intensity Estimation for the Permanental Process". 2) the Nystrom method also yields an approximate eigen expansion which has pros and cons to the method of the submission. For example, the Nystrom applies to any kernel (not just stationary) and yields a linear GP approximation, but requires some overhead for the setup. Given this submission is purely experimental, it would be nice to see comparisons.} 

Comparisons of the Hilbert space basis function approximations against other GP approximations, including the Nyström method, are provided by Solin and Särkkä (2020), which is cited prominently in our paper.

% Aki: R2 asks comparisons to Nystrom, but that comparison was
% already made by Solin and Särkkä so I don't think we should add that.


%\noindent \hdashrule{12.5cm}{0.2pt}{2mm 1pt}

%\nobibliography{references}


\end{document}


